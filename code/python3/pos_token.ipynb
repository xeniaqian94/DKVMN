{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (30,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1968555"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame.from_csv(\"../../data/duolingo/es_en.slam.20171218.train.csv\")\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history=df[['token','part_of_speech','correctness','user']].groupby(['user']).agg({'token':lambda x: tuple(x), \n",
    "                                   'part_of_speech':lambda x: tuple(x),'correctness':lambda x:tuple(x)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n",
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning: Columns (30,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning: Columns (31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Index(['user', 'countries', 'days', 'client', 'session', 'format', 'time',\n",
      "       'session_id', 'exercise_id', 'token_id', 'token', 'part_of_speech',\n",
      "       'morphological_features_Definite', 'morphological_features_Gender',\n",
      "       'morphological_features_Number', 'morphological_features_PronType',\n",
      "       'morphological_features_fPOS', 'dependency_label',\n",
      "       'dependency_edge_head', 'correctness', 'morphological_features_Mood',\n",
      "       'morphological_features_Person', 'morphological_features_Tense',\n",
      "       'morphological_features_VerbForm', 'morphological_features_Case',\n",
      "       'morphological_features_PrepCase', 'morphological_features_Poss',\n",
      "       'morphological_features_NumType', 'morphological_features_Reflex',\n",
      "       'morphological_features_Foreign', 'morphological_features_Degree',\n",
      "       'morphological_features_Polite'],\n",
      "      dtype='object')\n",
      "32\n",
      "32\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "def combine_train_valid_test_sheets(path):\n",
    "    train_df=pd.DataFrame.from_csv(path)\n",
    "    valid_df=pd.DataFrame.from_csv(path.replace(\"train\",\"dev\"))\n",
    "    test_df=pd.DataFrame.from_csv(path.replace(\"train\",\"test\"))\n",
    "    print(len(train_df.columns))\n",
    "    print(train_df.columns)\n",
    "    print(len(valid_df.columns))\n",
    "    print(len(test_df.columns))\n",
    "    print(set(train_df.columns).difference(set(valid_df.columns)))\n",
    "    print(set(train_df.columns).difference(set(test_df.columns)))\n",
    "    frames = [train_df, valid_df, test_df]\n",
    "    result = pd.concat(frames,keys=['train','dev','test'],names=['from', 'idx'])\n",
    "    return result\n",
    "    \n",
    "result=combine_train_valid_test_sheets(\"../../data/duolingo/es_en.slam.20171218.train.csv\")\n",
    "concat_result=result.reset_index(level=['from']).reset_index(drop=True)\n",
    "from collections import defaultdict\n",
    "user_list=list(concat_result['user'].unique())\n",
    "user2id=defaultdict(lambda:len(user2id))\n",
    "with open(\"user_id_mappingex.txt\",\"w\") as f:\n",
    "    for user in user_list:\n",
    "        f.write(user+\"\\t\"+str(user2id[user])+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../../data/duolingo/\"\n",
    "pos = \"part_of_speech\"\n",
    "token = \"token\"\n",
    "\n",
    "skill2id = {'unk':1}\n",
    "\n",
    "count = 1\n",
    "with open(directory+\"unigram_pos_train1.csv\",\"w\") as f:\n",
    "    for idx, row in user_history.iterrows():\n",
    "        total = len(row['part_of_speech'])\n",
    "        pos_tags = row['part_of_speech']\n",
    "        tokens = row['token']\n",
    "        train_skills_list = []\n",
    "        for i in range(total):\n",
    "            key = pos_tags[i] + tokens[i]\n",
    "            if key in skill2id:\n",
    "                train_skills_list.append(str(skill2id[key]))\n",
    "            else:\n",
    "                count += 1\n",
    "                skill2id[key] = count\n",
    "#                 print(str(skill2id[key]))\n",
    "                train_skills_list.append(str(skill2id[key]))\n",
    "        \n",
    "        train_correctness_list=[str(int(value)) for value in list(row['correctness'])]\n",
    "#         import pdb; pdb.set_trace()\n",
    "        f.write(str(len(train_skills_list))+\" # \"+str(user2id[idx])+\"\\n\"+str(\",\".join(train_skills_list))+\"\\n\"+\",\".join(train_correctness_list)+\"\\n\")\n",
    "        \n",
    "with open(directory + \"unigram_pos_id_mapping.txt\",\"w\") as f:\n",
    "    for skill in skill2id:\n",
    "        f.write(skill+\"\\t\"+str(skill2id[skill])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hsr/envs/rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame.from_csv(\"../../data/duolingo/es_en.slam.20171218.dev.csv\")\n",
    "\n",
    "user_history=df[['token','part_of_speech','correctness','user']].groupby(['user']).agg({'token':lambda x: tuple(x), \n",
    "                                   'part_of_speech':lambda x: tuple(x),'correctness':lambda x:tuple(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476\n",
      "270345\n"
     ]
    }
   ],
   "source": [
    "directory = \"../../data/duolingo/\"\n",
    "\n",
    "count = 0\n",
    "pos_count = 0\n",
    "with open(directory+\"unigram_pos_dev1.csv\",\"w\") as f:\n",
    "    for idx, row in user_history.iterrows():\n",
    "        total = len(row['part_of_speech'])\n",
    "        pos_tags = row['part_of_speech']\n",
    "        tokens = row['token']\n",
    "        skills_list = []\n",
    "        for i in range(total):\n",
    "            key = pos_tags[i] + tokens[i]\n",
    "            if key in skill2id:\n",
    "                skills_list.append(str(skill2id[key]))\n",
    "                pos_count += 1\n",
    "            else:\n",
    "                skills_list.append('1')\n",
    "                count += 1\n",
    "        \n",
    "        correctness_list=[str(int(value)) for value in list(row['correctness'])]\n",
    "        f.write(str(len(skills_list))+\" # \"+str(user2id[idx])+\"\\n\"+str(\",\".join(str(skills_list)))+\"\\n\"+\",\".join(correctness_list)+\"\\n\")\n",
    "    print(count)\n",
    "    print(pos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_csv(\"../../data/duolingo/es_en.slam.20171218.test.csv\")\n",
    "\n",
    "user_history=df[['token','part_of_speech','correctness','user']].groupby(['user']).agg({'token':lambda x: tuple(x), \n",
    "                                   'part_of_speech':lambda x: tuple(x),'correctness':lambda x:tuple(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../../data/duolingo/\"\n",
    "\n",
    "count = 0\n",
    "pos_count = 0\n",
    "with open(directory+\"unigram_pos_test.csv\",\"w\") as f:\n",
    "    for idx, row in user_history.iterrows():\n",
    "        total = len(row['part_of_speech'])\n",
    "        pos_tags = row['part_of_speech']\n",
    "        tokens = row['token']\n",
    "        skills_list = []\n",
    "        for i in range(total):\n",
    "            key = pos_tags[i] + tokens[i]\n",
    "            if key in skill2id:\n",
    "                skills_list.append(str(skill2id[key]))\n",
    "                pos_count += 1\n",
    "            else:\n",
    "                skills_list.append('1')\n",
    "                count += 1\n",
    "        \n",
    "        correctness_list=[str(int(value)) for value in list(row['correctness'])]\n",
    "        f.write(str(len(skills_list))+\" # \"+str(user2id[idx])+\"\\n\"+str(\",\".join(str(skills_list)))+\"\\n\"+\",\".join(correctness_list)+\"\\n\")\n",
    "    print(count)\n",
    "    print(pos_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
